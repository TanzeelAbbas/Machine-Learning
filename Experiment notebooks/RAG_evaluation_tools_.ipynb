{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wyWtzsaj8Cru"
      },
      "source": [
        "## ***Import Libraries***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T11:24:24.370762Z",
          "iopub.status.busy": "2024-02-27T11:24:24.369923Z",
          "iopub.status.idle": "2024-02-27T11:24:24.380270Z",
          "shell.execute_reply": "2024-02-27T11:24:24.379066Z",
          "shell.execute_reply.started": "2024-02-27T11:24:24.370723Z"
        },
        "id": "-DP0qdfEZqGY",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/tanzeel-abbas/.conda/envs/ta_ml_env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "# !pip install langchain\n",
        "# !pip install transformers\n",
        "# !pip install chromadb\n",
        "# !pip install sentence_transformers\n",
        "# !pip install accelerate\n",
        "# !pip install bitsandbytes\n",
        "# !pip install rank_bm25 > /dev/null\n",
        "# !pip install ragas\n",
        "# !pip install datasets\n",
        "import os, glob, textwrap, time\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
        "from transformers import pipeline\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.vectorstores.chroma import Chroma\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "from langchain import PromptTemplate\n",
        "from langchain.prompts import SystemMessagePromptTemplate, HumanMessagePromptTemplate, ChatPromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains.question_answering import load_qa_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5IADVQU3hhpG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/Pdf_Parsers_Txt_Files.zip, /content/Pdf_Parsers_Txt_Files.zip.zip or /content/Pdf_Parsers_Txt_Files.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "!unzip \"/content/Pdf_Parsers_Txt_Files.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yibhvAaH8W5h"
      },
      "source": [
        "## ***Load and chunk Documents***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T11:24:29.759625Z",
          "iopub.status.busy": "2024-02-27T11:24:29.759258Z",
          "iopub.status.idle": "2024-02-27T11:24:29.783133Z",
          "shell.execute_reply": "2024-02-27T11:24:29.782212Z",
          "shell.execute_reply.started": "2024-02-27T11:24:29.759599Z"
        },
        "id": "nk7A-t_1Z4eJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def loadSplitDocuments(file_path, chunk_size, chunk_overlap):\n",
        "  loader = TextLoader(file_path)\n",
        "  documents = loader.load()\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size = chunk_size, chunk_overlap= chunk_overlap)\n",
        "  text  = text_splitter.split_documents(documents)\n",
        "  return text\n",
        "\n",
        "\n",
        "text = loadSplitDocuments(\"Basic Structure of the Local High Voltage Product _parsed.txt\", chunk_size = 600, chunk_overlap=60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvorkLMfg_Fo"
      },
      "source": [
        "# ***Calculate rougeL metric***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-02-27T11:24:54.283914Z",
          "iopub.status.busy": "2024-02-27T11:24:54.283502Z",
          "iopub.status.idle": "2024-02-27T11:24:56.152797Z",
          "shell.execute_reply": "2024-02-27T11:24:56.151772Z",
          "shell.execute_reply.started": "2024-02-27T11:24:54.283880Z"
        },
        "id": "gOPhzZHmVQx8",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "questions_and_answers = [\n",
        "( \"Explore the interactions between the NGM app, BMS Manager, and Inverter Manager in ensuring efficient communication and data exchange across various system components, highlighting their roles in initialization and operational control.\",     \"The NGM app, BMS Manager, and Inverter Manager ensure efficient communication and data exchange by coordinating initialization and operational control across various system components.\"),\n",
        "( \"What actions does the NGM app take if it fails to establish registration with the Cloud during system startup, and how does this impact subsequent operations?\",     \"If the NGM app fails to establish registration with the Cloud during system startup, subsequent operations will be impacted, and the system will not function normally until Cloud registration is successful.\"),\n",
        "(    \"How does the NGM app facilitate the initialization process of various system components, and what is its role in ensuring proper communication among them?\",     \"The NGM app facilitates the initialization process by providing configurations to system components and ensuring communication channels are established.\")\n",
        "]\n",
        "\n",
        "results = [    \"The NGM app, BMS Manager, and Inverter Manager coordinate initialization and operational control across system components, ensuring efficient communication and data exchange.\",\n",
        "\"If the NGM app fails to register with the Cloud during startup, subsequent operations will be impacted until successful registration is achieved.\",\n",
        "\"The NGM app facilitates system initialization by providing configurations to components and ensuring communication channels are established.\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2024-02-27T11:24:59.680716Z",
          "iopub.status.busy": "2024-02-27T11:24:59.679905Z",
          "iopub.status.idle": "2024-02-27T11:24:59.687265Z",
          "shell.execute_reply": "2024-02-27T11:24:59.686087Z",
          "shell.execute_reply.started": "2024-02-27T11:24:59.680679Z"
        },
        "id": "ZIP4ZDsBVQx8",
        "outputId": "929b40a1-784e-4254-d37a-8f18427df55f",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'rouge1': 0.856242214322608, 'rouge2': 0.6607248960190136, 'rougeL': 0.7526813113359463, 'rougeLsum': 0.7526813113359463}\n"
          ]
        }
      ],
      "source": [
        "from evaluate import load\n",
        "\n",
        "rouge = load('rouge')\n",
        "scores = rouge.compute(predictions=results, references=[answer for _, answer in questions_and_answers])\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing text...\n",
            "Featurizing tokens\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Featurizing p: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizing text...\n",
            "Featurizing tokens\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Featurizing q: 100%|██████████| 2/2 [00:00<00:00, 27.42it/s]\n",
            "WARNING clustering 4 points to 2 centroids: please provide at least 78 training points\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "seed = 25\n",
            "performing clustering in lower dimension = 1\n",
            "Clustering 4 points in 2D to 2 clusters, redo 5 times, 500 iterations\n",
            "  Preprocessing in 0.00 s\n",
            "Outer iteration 0 / 5\n",
            "  Iteration 499 (11.11 s, search 0.06 s): objective=0.539912 imbalance=1.250 nsplit=0       \n",
            "Objective improved: keep new clusters\n",
            "Outer iteration 1 / 5\n",
            "  Iteration 499 (25.68 s, search 0.44 s): objective=0.511143 imbalance=1.000 nsplit=0       \n",
            "Objective improved: keep new clusters\n",
            "Outer iteration 2 / 5\n",
            "  Iteration 499 (40.64 s, search 0.63 s): objective=0.539912 imbalance=1.250 nsplit=0       \n",
            "Outer iteration 3 / 5\n",
            "  Iteration 499 (54.66 s, search 0.80 s): objective=0.511143 imbalance=1.000 nsplit=0       \n",
            "Outer iteration 4 / 5\n",
            "  Iteration 499 (68.87 s, search 1.07 s): objective=0.511143 imbalance=1.000 nsplit=0       \n",
            "kmeans time: 68.88 s\n",
            "total discretization time: 68.88 seconds\n",
            "_____________ 1.0\n"
          ]
        }
      ],
      "source": [
        "rouge = load('mauve')\n",
        "scores = rouge.compute(predictions=[\"hello\", \"haider\" ], references=[\"hello\", \"hi\"])\n",
        "print(\"_____________\",scores.mauve)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/tanzeel-\n",
            "[nltk_data]     abbas/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>reference</th>\n",
              "      <th>Model A</th>\n",
              "      <th>Model B</th>\n",
              "      <th>Model C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of France?</td>\n",
              "      <td>The capital of France is Paris.</td>\n",
              "      <td>Paris is the capital of France.</td>\n",
              "      <td>Capital of France is Paris.</td>\n",
              "      <td>Capital of France was Paris.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                           prompt                        reference   \n",
              "0  What is the capital of France?  The capital of France is Paris.  \\\n",
              "\n",
              "                           Model A                      Model B   \n",
              "0  Paris is the capital of France.  Capital of France is Paris.  \\\n",
              "\n",
              "                        Model C  \n",
              "0  Capital of France was Paris.  "
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from falcon_evaluate.fevaluate_results import ModelScoreSummary\n",
        "from falcon_evaluate.fevaluate_plot import ModelPerformancePlotter\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'prompt': [\n",
        "        \"What is the capital of France?\"\n",
        "    ],\n",
        "    'reference': [\n",
        "        \"The capital of France is Paris.\"\n",
        "    ],\n",
        "    'Model A': [\n",
        "        \"Paris is the capital of France.\"\n",
        "    ],\n",
        "    'Model B': [\n",
        "        \"Capital of France is Paris.\"\n",
        "    ],\n",
        "    'Model C': [\n",
        "        \"Capital of France was Paris.\"\n",
        "    ],\n",
        "})\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>reference</th>\n",
              "      <th>Model A</th>\n",
              "      <th>Model B</th>\n",
              "      <th>Model C</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of Portugal?</td>\n",
              "      <td>The capital of Portugal is Lisbon.</td>\n",
              "      <td>Lisbon is the capital of Portugal.</td>\n",
              "      <td>Portugal's capital is Lisbon.</td>\n",
              "      <td>Is Lisbon the main city of Portugal?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             prompt                           reference   \n",
              "0  What is the capital of Portugal?  The capital of Portugal is Lisbon.  \\\n",
              "\n",
              "                              Model A                        Model B   \n",
              "0  Lisbon is the capital of Portugal.  Portugal's capital is Lisbon.  \\\n",
              "\n",
              "                                Model C  \n",
              "0  Is Lisbon the main city of Portugal?  "
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Example DataFrame\n",
        "data = {\n",
        "    \"prompt\": [\"What is the capital of Portugal?\"],\n",
        "    \"reference\": [\"The capital of Portugal is Lisbon.\"],\n",
        "    \"Model A\": [\"Lisbon is the capital of Portugal.\"],\n",
        "    \"Model B\": [\"Portugal's capital is Lisbon.\"],\n",
        "    \"Model C\": [\"Is Lisbon the main city of Portugal?\"]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>reference</th>\n",
              "      <th>Model A</th>\n",
              "      <th>Model B</th>\n",
              "      <th>Model C</th>\n",
              "      <th>Model A-reliability-Score</th>\n",
              "      <th>Model B-reliability-Score</th>\n",
              "      <th>Model C-reliability-Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>What is the capital of Portugal?</td>\n",
              "      <td>The capital of Portugal is Lisbon.</td>\n",
              "      <td>Lisbon is the capital of Portugal.</td>\n",
              "      <td>Portugal's capital is Lisbon.</td>\n",
              "      <td>Is Lisbon the main city of Portugal?</td>\n",
              "      <td>{'hallucination_score': 1.0}</td>\n",
              "      <td>{'hallucination_score': 1.0}</td>\n",
              "      <td>{'hallucination_score': 0.22}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             prompt                           reference   \n",
              "0  What is the capital of Portugal?  The capital of Portugal is Lisbon.  \\\n",
              "\n",
              "                              Model A                        Model B   \n",
              "0  Lisbon is the capital of Portugal.  Portugal's capital is Lisbon.  \\\n",
              "\n",
              "                                Model C     Model A-reliability-Score   \n",
              "0  Is Lisbon the main city of Portugal?  {'hallucination_score': 1.0}  \\\n",
              "\n",
              "      Model B-reliability-Score      Model C-reliability-Score  \n",
              "0  {'hallucination_score': 1.0}  {'hallucination_score': 0.22}  "
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from falcon_evaluate.fevaluate_reliability import Reliability_evaluator\n",
        "\n",
        "Reliability_eval = Reliability_evaluator()\n",
        "results_df = Reliability_eval.predict_hallucination_score(df)\n",
        "results_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/tanzeel-\n",
            "[nltk_data]     abbas/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>prompt</th>\n",
              "      <th>Fairness_eval</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The man from Somalia was grateful to his new h...</td>\n",
              "      <td>{'stereotype_score': [{'label': 'stereotype_ra...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              prompt   \n",
              "0  The man from Somalia was grateful to his new h...  \\\n",
              "\n",
              "                                       Fairness_eval  \n",
              "0  {'stereotype_score': [{'label': 'stereotype_ra...  "
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from falcon_evaluate.fairness import FairnessEvaluator\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "# Example DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'prompt': [\n",
        "        \"The man from Somalia was grateful to his new homeland. He was a refugee from extremists and warlords\"\n",
        "    ]\n",
        "})\n",
        "\n",
        "# Evaluate fairness\n",
        "evaluator = FairnessEvaluator()\n",
        "evaluated_df = evaluator.evaluate(df)\n",
        "evaluated_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 4501723,
          "sourceId": 7709861,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30648,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.1.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
